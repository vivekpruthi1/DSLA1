---
title: "R Notebook"
output: html_notebook
---

# #######################Solution to mushrooms problem using ANN #################################

Helper funtion to create a directory on local filesystem
```{r}
mkdirs <- function(fp) {
    if(!file.exists(fp)) {
        dir.create(dirname(fp), showWarnings=FALSE, recursive = TRUE)
    }
} 
```

Helper function to install and load any package
```{r}
# Function to Install and Load R Packages
installAndLoad <- function(Required_Packages)
{
    Remaining_Packages <- Required_Packages[!(Required_Packages %in% installed.packages()[,"Package"])];

    if(length(Remaining_Packages)) 
    {
        install.packages(Remaining_Packages);
    }
    for(package_name in Required_Packages)
    {
        library(package_name,character.only=TRUE,quietly=TRUE);
    }
}
```

Following code will load mushrooms data into dataframe. It will try to load the file from "data/mushrooms.csv" file on local computer. If its not available, it will download it from web and store it locally so we don't have to download it again when we rerun the program again.

```{r}
loadData <- function(filepath, url, header=FALSE) {
  # load the CSV file from the local directory if it exists
  if(file.exists(filepath))
    dataset <- read.csv(filename, header=TRUE)
  else {
    # load the library
    installAndLoad(c("RCurl"));
    # download the file
    downloaded <- getURL(url, ssl.verifypeer=FALSE)
    # treat the text data as a steam so we can read from it
    connection <- textConnection(downloaded)
    # parse the downloaded data as CSV
    dataset <- read.csv(connection, header=header)
    # Add headers to dataset
    column_names = c("class", "cap-shape", "cap-surface", "cap-color", "bruises", "odor",
                     "gill-attachment", "gill-spacing", "gill-size", "gill-color", "stalk-shape",
                     "stalk-root", "stalk-surface-above-ring", "stalk-surface-below-ring",
                     "stalk-color-above-ring", "stalk-color-below-ring", "veil-type", "veil-color",
                     "ring-number", "ring-type", "spore-print-color", "population", "habitat")

    
    colnames(dataset) <- column_names
    #Expand e and p to edible and posonous
    dataset$class = sapply(dataset$class, function(x){ifelse(x=='e', 'edible', 'poisonous')})
    #Save file locally
    if(!file.exists(filepath)) {
      mkdirs(filepath)
    }
    write.csv(file=filepath, x=dataset, row.names = FALSE)
  }
  
  #return dataset
  dataset
}
```

*********************************Main program start here**********************************
Load data file
```{r}
# define the filename
filename <- file.path(getwd(), "data", "mushrooms.csv")
# specify the URL for the mushroom data CSV
url <-'https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.data'
#Call loadData function
mushrooms_data <- loadData(filename, url)
```

Check dataset

```{r}
# preview the first 6 rows
head(mushrooms_data)
```
Explore some details about data. We have 22 predictors and its a binary classification problem
```{r}
#Dimentions of data
dim(mushrooms_data)
```
```{r}
#Summary of Data
summary(mushrooms_data)
```
# veil.type is same for all observations. We can drop it
```{r}
mushroom$veil_type = NULL  # remove veil_type because all are partial, unnecessary column
```

```{r}
#structure of data
str(mushrooms_data)
```

Manage missing data. We don't have any missing data
```{r}
sapply(mushrooms_data, function(x) sum(is.na(x)))
sum(is.na(mushrooms_data))
```

Data Analysis
```{r}
installAndLoad(c('caret'))
head(mushrooms_data[, 2:5])
par(mfrow=c(2,2))
plot(table(mushrooms_data$odor, mushrooms_data$class), col = 'blue')
plot(table(mushrooms_data$stalk.root, mushrooms_data$class), col = 'blue')
plot(table(mushrooms_data$gill.color, mushrooms_data$class), col = 'blue')
plot(table(mushrooms_data$gill.spacing, mushrooms_data$class), col = 'blue')
table(mushrooms_data$odor, mushrooms_data$class)
table(mushrooms_data$stalk.root, mushrooms_data$class)
table(mushrooms_data$gill.color, mushrooms_data$class)
table(mushrooms_data$gill.spacing, mushrooms_data$class)
```


Split data into training and test sets
```{r}
#Split Dataset into training and test sets
# install.packages('caTools')
installAndLoad('caTools')
set.seed(1)
split = sample.split(mushrooms_data$class, SplitRatio = 0.8)
training_set = subset(mushrooms_data, split == TRUE)
test_set = subset(mushrooms_data, split == FALSE)
```

Install H2O if it is not installed already
```{r}
# Install h2o package if not installed already
if (!("h2o" %in% rownames(installed.packages()))) {
  # Next, we download packages that H2O depends on.
  installAndLoad(c("statmod","RCurl","jsonlite"))
  # Now we download, install and initialize the H2O package for R.
  install.packages("h2o", type="source", repos="http://h2o-release.s3.amazonaws.com/h2o/rel-vajda/4/R")
}
```
Finally, let's load H2O and start up an H2O cluster
```{r}
library(h2o)
h2o.init(nthreads = -1)
h2o.removeAll() ## clean slate - just in case the cluster was already running
```

Fitting ANN to training set
```{r}
classifier = h2o.deeplearning(y = 'class',
                              training_frame = as.h2o(training_set),
                              activation = 'Rectifier',
                              hidden = c(6,6),
                              epochs = 10,
                              train_samples_per_iteration = -2)
```
Look at summry of the model
```{r}
summary(classifier)
```
Predicting test set results
```{r}
prob_pred = h2o.predict(classifier, newdata = as.h2o(test_set[-1]))
y_pred = prob_pred$predict
y_pred = as.vector(y_pred)
```

Model accuracy
```{r}
# validation accuracy
plot(classifier)
```
```{r}
par(mfrow=c(2,2))
plot(classifier, timestep = "epochs", metric = "classification_error")
plot(classifier, timestep = "epochs", metric = "rmse")
plot(classifier, timestep = "epochs", metric = "logloss")
plot(classifier, timestep = "duration", metric = "logloss")
```

Scoring history
```{r}
h2o.scoreHistory(classifier)
```

Apply grid search to find optimal hyperparameters. We will test with activation, L1, and L2
```{r}
activation_opt <- c("Rectifier", "Maxout", "Tanh")
l1_opt <- c(0, 0.00001, 0.0001, 0.001, 0.01)
l2_opt <- c(0, 0.00001, 0.0001, 0.001, 0.01)

hyper_params <- list(activation = activation_opt, l1 = l1_opt, l2 = l2_opt)
search_criteria <- list(strategy = "RandomDiscrete", max_runtime_secs = 600)

splits <- h2o.splitFrame(as.h2o(training_set), ratios = 0.8, seed = 1)

dl_grid <- h2o.grid("deeplearning", x = colnames(training_set[,-1]), y = 'class',
                    grid_id = "dl_grid",
                    training_frame = splits[[1]],
                    validation_frame = splits[[2]],
                    seed = 1,
                    hidden = c(20,20),
                    hyper_params = hyper_params,
                    search_criteria = search_criteria)

dl_gridperf <- h2o.getGrid(grid_id = "dl_grid", 
                           sort_by = "accuracy", 
                           decreasing = TRUE)
```
```{r}
print(dl_gridperf)
```

Get best model out
```{r}
best_dl_model_id <- dl_gridperf@model_ids[[1]]
best_dl <- h2o.getModel(best_dl_model_id)

best_dl_perf <- h2o.performance(model = best_dl, newdata = as.h2o(test_set))
h2o.mse(best_dl_perf)
```

Compare best model with our original model
```{r}
print('Best Model performance:')
h2o.confusionMatrix(best_dl_perf)
h2o.mse(best_dl_perf)
```
Original classifier
```{r}
print('Original Model performance:')
h2o.confusionMatrix(classifier)
h2o.mse(classifier)
```
Summary of best model:
```{r}
summary(best_dl_perf)
plot(best_dl_perf)
```

```{r}
h2o.shutdown()
```

